import streamlit as st
import numpy as np
import json
import pickle
import faiss
import os

st.set_page_config(page_title="Two-Tower Recommender", page_icon="ğŸ®", layout="wide")

# â”€â”€ Load data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def load_data():
    DATA_DIR = os.environ.get("DATA_DIR", "streamlit_data")
    tt_user = np.load(f"{DATA_DIR}/tt_user_embs.npy")
    tt_item = np.load(f"{DATA_DIR}/tt_item_embs.npy")
    mf_user = np.load(f"{DATA_DIR}/mf_user_embs.npy")
    mf_item = np.load(f"{DATA_DIR}/mf_item_embs.npy")
    text_embs = np.load(f"{DATA_DIR}/text_embs.npy")
    with open(f"{DATA_DIR}/item_info.json") as f:
        item_info = {int(k): v for k, v in json.load(f).items()}
    with open(f"{DATA_DIR}/user_history.pkl", "rb") as f:
        user_history = pickle.load(f)
    with open(f"{DATA_DIR}/stats.json") as f:
        stats = json.load(f)
    # Build FAISS indices
    tt_index = faiss.IndexFlatIP(tt_item.shape[1])
    tt_index.add(tt_item)
    mf_index = faiss.IndexFlatIP(mf_item.shape[1])
    mf_index.add(mf_item)
    return {
        "tt_user": tt_user, "tt_item": tt_item,
        "mf_user": mf_user, "mf_item": mf_item,
        "tt_index": tt_index, "mf_index": mf_index,
        "text_embs": text_embs,
        "item_info": item_info, "user_history": user_history,
        "stats": stats,
    }

data = load_data()

def get_item_display(idx):
    info = data["item_info"].get(idx, {})
    title = info.get("title", "Unknown")
    cat = info.get("category", "")
    rating = info.get("rating", None)
    price = info.get("price", None)
    r_str = f"â­ {rating:.1f}" if rating else ""
    p_str = f"${price:.0f}" if price else ""
    return title, cat, r_str, p_str

def recommend(user_emb, index, history_set, k=10):
    scores, indices = index.search(user_emb.reshape(1, -1), k + len(history_set) + 10)
    recs = []
    for idx, score in zip(indices[0], scores[0]):
        if int(idx) not in history_set and len(recs) < k:
            recs.append((int(idx), float(score)))
    return recs

# â”€â”€ Sidebar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.title("ğŸ® Two-Tower RecSys")
st.sidebar.markdown("Amazon Video Games 2023")
st.sidebar.markdown("---")

page = st.sidebar.radio("Navigate", [
    "ğŸ  Overview",
    "ğŸ‘¤ User Recommendations",
    "ğŸ†• Cold-Start Demo",
    "ğŸ“Š Model Comparison",
])

# â”€â”€ Page 1: Overview â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if page == "ğŸ  Overview":
    st.title("ğŸ® Two-Tower Recommendation System")
    st.markdown("### Deep Learning Recommender with 12-Variant Ablation Study")

    col1, col2, col3 = st.columns(3)
    s = data["stats"]
    col1.metric("Users", f"{s['n_users']:,}")
    col2.metric("Items", f"{s['n_items']:,}")
    col3.metric("Sparsity", "99.97%")

    st.markdown("---")
    st.markdown("### Model Performance (Full Ranking)")

    perf_data = {
        "Model": ["MF (BPR)", "Two-Tower v5", "LightGCN"],
        "HR@10": [s["results"]["mf_hr10_full"], s["results"]["tt_hr10_full"], s["results"]["lgcn_hr10_full"]],
        "Type": ["Collaborative", "Content + Sequential", "Graph Neural Network"],
        "Cold-Start": ["âŒ No", "âœ… Yes", "âŒ No"],
        "FAISS Deployable": ["âš ï¸ Partial", "âœ… Yes (<1ms)", "âŒ No"],
    }
    st.dataframe(perf_data, hide_index=True, use_container_width=True)

    st.markdown("---")
    st.markdown("### Architecture")
    st.code("""
    Two-Tower (retrieval)  â†’  FAISS Index (<1ms)  â†’  Top 1000 candidates
                                                          â”‚
                                                    LightGCN (re-rank)
                                                          â”‚
                                                    Top 10 shown to user
    """)

    st.markdown("---")
    st.markdown("### 12-Variant Ablation Summary")
    ablation = {
        "Version": ["v1","v2","v3","v4","v4b","v4-BPR","v5","v5b","v5c","v6","v7","v8"],
        "Change": ["Baseline","MSE distill","Cosine distill","+ Title text",
                   "Batch 1024","BPR + hard neg","+ GRU sequence","+ Rich text",
                   "LightGCN init","Curriculum neg","+ CLIP images","FM-style"],
        "HR@10": [0.6195,0.6210,0.6195,0.6355,0.6280,0.1520,0.6395,0.6385,
                  0.6330,0.6355,0.6355,0.6305],
        "Verdict": ["â€”","âŒ Gradient drowned","âŒ Structural blind","âœ… +2.6%",
                    "âŒ Too many neg","âŒ Collapsed","âœ… Best","âŒ Noisy text",
                    "âŒ Scrambled","âŒ Hurt","âŒ No help","ğŸ“Š Interpretable"],
    }
    st.dataframe(ablation, hide_index=True, use_container_width=True)

# â”€â”€ Page 2: User Recommendations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
elif page == "ğŸ‘¤ User Recommendations":
    st.title("ğŸ‘¤ Recommendations for Existing Users")

    col1, col2 = st.columns([1, 1])
    with col1:
        user_id = st.number_input("User ID", min_value=0,
                                   max_value=data["stats"]["n_users"]-1, value=100)
        model_choice = st.selectbox("Model", ["Two-Tower v5", "Matrix Factorization", "Both"])

    # Show user history
    history = data["user_history"].get(user_id, [])
    history_set = set(history)

    st.markdown(f"### Purchase History ({len(history)} items)")
    hist_cols = st.columns(min(5, max(1, len(history[:10]))))
    for i, item_idx in enumerate(history[:10]):
        with hist_cols[i % len(hist_cols)]:
            title, cat, rating, price = get_item_display(item_idx)
            st.markdown(f"**{title[:40]}**")
            st.caption(f"{cat} {rating} {price}")

    st.markdown("---")

    if model_choice in ["Two-Tower v5", "Both"]:
        st.markdown("### ğŸ¤– Two-Tower v5 Recommendations")
        tt_emb = data["tt_user"][user_id]
        tt_recs = recommend(tt_emb, data["tt_index"], history_set, k=10)
        for rank, (idx, score) in enumerate(tt_recs, 1):
            title, cat, rating, price = get_item_display(idx)
            st.markdown(f"**{rank}. {title}** â€” {cat} {rating} {price} (score: {score:.3f})")

    if model_choice in ["Matrix Factorization", "Both"]:
        st.markdown("### ğŸ“ Matrix Factorization Recommendations")
        mf_emb = data["mf_user"][user_id]
        mf_recs = recommend(mf_emb, data["mf_index"], history_set, k=10)
        for rank, (idx, score) in enumerate(mf_recs, 1):
            title, cat, rating, price = get_item_display(idx)
            st.markdown(f"**{rank}. {title}** â€” {cat} {rating} {price} (score: {score:.3f})")

# â”€â”€ Page 3: Cold-Start Demo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
elif page == "ğŸ†• Cold-Start Demo":
    st.title("ğŸ†• Cold-Start: New User Recommendations")
    st.markdown("""
    **This is where Two-Tower shines.** Select a few games you like,
    and Two-Tower will recommend more â€” even though you are a brand new user
    with NO purchase history. MF and LightGCN cannot do this.
    """)

    # Let user search for games
    all_titles = {idx: data["item_info"].get(idx, {}).get("title", "Unknown")
                  for idx in range(data["stats"]["n_items"])}

    # Pre-built scenarios
    scenario = st.selectbox("Choose a scenario (or pick custom games below)", [
        "Custom",
        "Souls-like Gamer (Dark Souls, Elden Ring, Sekiro)",
        "Nintendo Fan (Mario, Zelda, Pokemon accessories)",
        "FPS Player (Call of Duty, Battlefield, Halo)",
    ])

    if scenario == "Custom":
        search_term = st.text_input("Search for a game title:")
        if search_term:
            matches = [(idx, t) for idx, t in all_titles.items()
                       if search_term.lower() in t.lower()][:20]
            if matches:
                selected = st.multiselect(
                    "Select games you like:",
                    options=[idx for idx, t in matches],
                    format_func=lambda x: all_titles[x][:60]
                )
            else:
                st.warning("No games found. Try a different search.")
                selected = []
        else:
            selected = []
    else:
        # Map scenarios to item indices
        scenario_items = {
            "Souls-like Gamer (Dark Souls, Elden Ring, Sekiro)":
                ["Dark Souls", "Elden Ring", "Sekiro"],
            "Nintendo Fan (Mario, Zelda, Pokemon accessories)":
                ["Mario", "Zelda", "Pokemon"],
            "FPS Player (Call of Duty, Battlefield, Halo)":
                ["Call of Duty", "Battlefield", "Halo"],
        }
        keywords = scenario_items[scenario]
        selected = []
        for kw in keywords:
            for idx, t in all_titles.items():
                if kw.lower() in t.lower():
                    selected.append(idx)
                    break

    if len(selected) >= 2:
        st.markdown("### Your browsing history:")
        for idx in selected:
            title, cat, rating, price = get_item_display(idx)
            st.markdown(f"- **{title}** ({cat})")

        # Compute cold-start embedding using text similarity
        # Simple approach: average the text embeddings of selected items
        selected_text = data["text_embs"][selected]
        avg_emb = selected_text.mean(axis=0, keepdims=True)

        # Find nearest items in Two-Tower space
        # Project through item tower conceptually: use text similarity
        # to TT item embeddings
        avg_tt = data["tt_item"][selected].mean(axis=0, keepdims=True)
        avg_tt = avg_tt / np.linalg.norm(avg_tt, axis=1, keepdims=True)

        scores, indices = data["tt_index"].search(avg_tt.astype(np.float32), 20)
        selected_set = set(selected)

        st.markdown("### ğŸ¤– Two-Tower Recommendations")
        count = 0
        for idx, score in zip(indices[0], scores[0]):
            if int(idx) not in selected_set and count < 10:
                title, cat, rating, price = get_item_display(int(idx))
                st.markdown(f"**{count+1}. {title}** â€” {cat} {rating} {price} (similarity: {score:.3f})")
                count += 1

        st.markdown("---")
        col1, col2 = st.columns(2)
        with col1:
            st.error("âŒ **MF**: Cannot recommend â€” no user ID embedding exists")
        with col2:
            st.error("âŒ **LightGCN**: Cannot recommend â€” user not in graph")
        st.success("âœ… **Two-Tower**: Works! Uses text embeddings + content features")
    else:
        st.info("Select at least 2 games to get recommendations.")

# â”€â”€ Page 4: Model Comparison â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
elif page == "ğŸ“Š Model Comparison":
    st.title("ğŸ“Š Model Comparison & Analysis")

    tab1, tab2, tab3 = st.tabs(["Performance", "Latency", "Trade-offs"])

    with tab1:
        st.markdown("### Sampled Evaluation (100 negatives)")
        st.markdown("""
        | Model | HR@10 | NDCG@10 |
        |---|---|---|
        | MF (BPR) | **0.6755** | **0.4516** |
        | Two-Tower v5 | 0.6395 | 0.4148 |
        | LightGCN | **0.7285** | **0.4940** |
        """)

        st.markdown("### Full Ranking (all 26,354 items)")
        st.markdown("""
        | Model | HR@5 | HR@10 | HR@20 | NDCG@10 | NDCG@20 |
        |---|---|---|---|---|---|
        | MF | 0.0270 | 0.0420 | 0.0650 | 0.0228 | 0.0285 |
        | Two-Tower | 0.0190 | 0.0270 | 0.0410 | 0.0125 | 0.0161 |
        | LightGCN | **0.0300** | **0.0440** | **0.0740** | **0.0227** | **0.0302** |
        """)

        st.markdown("### Performance by User Sparsity")
        st.markdown("""
        | User Bucket | # Users | MF HR@10 | TT HR@10 | Winner |
        |---|---|---|---|---|
        | 5-7 purchases | 25,477 | 0.6780 | 0.6700 | MF |
        | 8-15 purchases | 15,737 | 0.6680 | 0.6360 | MF |
        | 16-30 purchases | 4,178 | 0.6500 | 0.6220 | MF |
        | 31+ purchases | 1,397 | 0.5780 | 0.5340 | MF |
        | **New user (0 purchases)** | **âˆ** | **IMPOSSIBLE** | **âœ… Works** | **Two-Tower** |
        """)

    with tab2:
        st.markdown("### FAISS Retrieval Latency")
        st.markdown("""
        | Index Type | Latency / Query | Queries/Second |
        |---|---|---|
        | HNSW (graph) | **29 Î¼s** | 34,483 |
        | IVF (approximate) | 35 Î¼s | 28,571 |
        | Flat (exact) | 310 Î¼s | 3,226 |
        | Brute-force GPU | 894 Î¼s | 1,119 |
        """)
        st.markdown("Two-Tower serves 34,000 users/second on a single CPU core.")

    with tab3:
        st.markdown("### The Retrieval-Ranking Trade-off")
        st.markdown("""
        | Aspect | Two-Tower | MF | LightGCN |
        |---|---|---|---|
        | **Accuracy (known users)** | 3rd | 2nd | 1st |
        | **Cold-start (new users)** | âœ… Yes | âŒ No | âŒ No |
        | **Cold-start (new items)** | âœ… Yes | âŒ No | âŒ No |
        | **FAISS deployable** | âœ… <1ms | âš ï¸ Need normalization | âŒ Need graph |
        | **Content-aware** | âœ… Text + features | âŒ IDs only | âŒ IDs only |
        | **Industry role** | Retrieval (top 1000) | Baseline | Ranking (top 10) |
        """)

        st.markdown("### FM Gate Weights: What the Model Learned")
        st.markdown("""
        The FM-style model (v8) learned interpretable weights showing
        how much each signal source contributes:

        **User representation:** ID embeddings = 62%, GRU sequence = 28%, Features = 10%

        **Item representation:** ID embeddings = 54%, Features = 22%, Text = 23%

        This proves that on ultra-sparse data (99.97%), collaborative ID signals
        carry 2-3x more weight than all content features combined.
        """)

st.sidebar.markdown("---")
st.sidebar.markdown("Built by [Nidhi](https://github.com/nidhi1603)")
st.sidebar.markdown("[GitHub Repo](https://github.com/nidhi1603/Two_Tower_Recommendation_System)")
